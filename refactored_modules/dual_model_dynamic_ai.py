import os
import re
import json
import asyncio
import aiohttp
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, date
import logging
from decimal import Decimal

logger = logging.getLogger(__name__)

class DualModelDynamicAISystem:
    """üß† ‡∏£‡∏∞‡∏ö‡∏ö AI 2 ‡πÇ‡∏°‡πÄ‡∏î‡∏•: SQL Generation + Natural Language Response"""
    
    def __init__(self, database_handler, original_ollama_client):
        self.db_handler = database_handler
        self.original_ollama_client = original_ollama_client
        
        # Model Configuration
        self.SQL_MODEL = "mannix/defog-llama3-sqlcoder-8b:latest"
        self.NL_MODEL = "llama3.2:3b"
        
        # Ollama Configuration
        self.ollama_base_url = os.getenv('OLLAMA_BASE_URL', 'http://52.74.36.160:12434')
        self.request_timeout = 60
        
        # Caching System
        self.schema_cache = {}
        self.sql_cache = {}
        self.cache_ttl = 3600
        
        logger.info(f"üöÄ Dual-Model Dynamic AI initialized:")
        logger.info(f"   üìù SQL Generation: {self.SQL_MODEL}")
        logger.info(f"   üí¨ Response Generation: {self.NL_MODEL}")
    
    # =========================================================================
    # üéØ MAIN PROCESSING PIPELINE
    # =========================================================================
    
    async def process_any_question(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """üéØ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç main processing ‡πÉ‡∏´‡πâ‡∏°‡∏µ error recovery"""
        
        try:
            start_time = datetime.now()
            logger.info(f"üöÄ [DUAL-MODEL] Processing: {question}")
            
            # Step 1: Schema Discovery with error handling
            try:
                actual_schema = await self._discover_complete_schema(tenant_id)
                if not actual_schema:
                    raise Exception("No schema discovered")
            except Exception as schema_error:
                logger.error(f"‚ùå Schema discovery failed: {schema_error}")
                # ‡πÉ‡∏ä‡πâ fallback schema
                actual_schema = self._get_fallback_schema()
            
            # Step 2: SQL Generation with multiple attempts
            sql_attempts = 0
            max_attempts = 2
            
            while sql_attempts < max_attempts:
                sql_attempts += 1
                
                try:
                    sql_result = await self._generate_sql_with_specialist(question, actual_schema, tenant_id)
                    
                    if sql_result["success"]:
                        break
                    else:
                        logger.warning(f"‚ö†Ô∏è SQL generation attempt {sql_attempts} failed")
                        if sql_attempts == max_attempts:
                            return await self._create_fallback_response(question, tenant_id, actual_schema)
                        
                except Exception as sql_error:
                    logger.error(f"‚ùå SQL generation attempt {sql_attempts} error: {sql_error}")
                    if sql_attempts == max_attempts:
                        return await self._create_fallback_response(question, tenant_id, actual_schema)
            
            # Step 3: Execute SQL
            try:
                results = await self._execute_sql_safely(sql_result["sql_query"], tenant_id)
            except Exception as exec_error:
                logger.error(f"‚ùå SQL execution failed: {exec_error}")
                return await self._create_fallback_response(question, tenant_id, actual_schema)
            
            # Step 4: Generate Natural Response
            try:
                if results:
                    natural_response = await self._generate_natural_response(
                        question, results, sql_result["sql_query"], tenant_id
                    )
                else:
                    natural_response = f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\n\n‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞:\n‚Ä¢ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏\n‚Ä¢ ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ\n\n‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"
                    
            except Exception as response_error:
                logger.error(f"‚ùå NL generation failed: {response_error}")
                natural_response = self._create_simple_formatted_response(question, results)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "answer": natural_response,
                "success": len(results) > 0,
                "sql_query": sql_result["sql_query"],
                "results_count": len(results),
                "question_analysis": sql_result["analysis"],
                "data_source_used": "dual_model_dynamic_ai_fixed",
                "system_used": "sql_specialist_plus_nl_generator", 
                "processing_time": processing_time,
                "models_used": {
                    "sql_generation": self.SQL_MODEL,
                    "response_generation": self.NL_MODEL
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå [DUAL-MODEL] Complete failure: {e}")
            return self._create_error_response(str(e), tenant_id)     
        
    def _get_fallback_schema(self) -> Dict[str, Any]:
        """üÜò ‡∏™‡∏£‡πâ‡∏≤‡∏á fallback schema ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡πÑ‡∏î‡πâ"""
        
        return {
            "sales2023": {
                "columns": [
                    {"name": "id", "type": "integer"},
                    {"name": "customer_name", "type": "varchar"},
                    {"name": "service_contact_", "type": "integer"},
                    {"name": "job_no", "type": "varchar"},
                    {"name": "description", "type": "varchar"}
                ]
            },
            "sales2024": {
                "columns": [
                    {"name": "id", "type": "integer"},
                    {"name": "customer_name", "type": "varchar"},
                    {"name": "service_contact_", "type": "integer"},
                    {"name": "job_no", "type": "varchar"},
                    {"name": "description", "type": "varchar"}
                ]
            },
            "spare_part": {
                "columns": [
                    {"name": "id", "type": "integer"},
                    {"name": "product_name", "type": "varchar"},
                    {"name": "unit_price", "type": "varchar"},
                    {"name": "balance", "type": "integer"}
                ]
            }
        }

    async def _create_no_results_response(self, question: str, tenant_id: str) -> str:
        """üì≠ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        
        suggestions = [
            "‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤",
            "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå",
            "‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏∂‡πâ‡∏ô"
        ]
        
        nl_prompt = f"""‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: {question}

    ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà:
    1. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    2. ‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏î‡πâ‡∏ú‡∏•
    3. ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ

    ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£:"""

        try:
            response = await self._call_ollama_model(self.NL_MODEL, nl_prompt)
            return self._clean_nl_response(response)
        except:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\n\n‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"

    # =============================================================================
    # üß™ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DEBUGGING - ‡πÄ‡∏û‡∏¥‡πà‡∏° Sync Version Functions
    # =============================================================================

    def _get_database_connection_sync(self, tenant_id: str):
        """üîó Sync version ‡∏Ç‡∏≠‡∏á database connection"""
        
        try:
            if hasattr(self.db_handler, 'get_database_connection'):
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å sync function
                return self.db_handler.get_database_connection(tenant_id)
            else:
                # Manual connection
                from .tenant_config import TenantConfigManager
                import psycopg2
                
                config_manager = TenantConfigManager()
                tenant_config = config_manager.tenant_configs[tenant_id]
                
                return psycopg2.connect(
                    host=tenant_config.db_host,
                    port=tenant_config.db_port,
                    database=tenant_config.db_name,
                    user=tenant_config.db_user,
                    password=tenant_config.db_password
                )
        except Exception as e:
            logger.error(f"‚ùå Sync database connection failed: {e}")
            raise

    # =========================================================================
    # üîç SCHEMA DISCOVERY
    # =========================================================================
    
    async def _discover_complete_schema(self, tenant_id: str) -> Dict[str, Any]:
        """üîç ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö schema - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á async ‡πÅ‡∏•‡∏∞ sync"""
        
        cache_key = f"schema_{tenant_id}"
        if cache_key in self.schema_cache:
            cache_time = self.schema_cache[cache_key]["timestamp"]
            if (datetime.now() - cache_time).total_seconds() < self.cache_ttl:
                return self.schema_cache[cache_key]["data"]
        
        try:
            # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ database connection ‡πÄ‡∏õ‡πá‡∏ô async ‡∏´‡∏£‡∏∑‡∏≠ sync
            try:
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ async version ‡∏Å‡πà‡∏≠‡∏ô
                if hasattr(self.db_handler, 'get_database_connection'):
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô coroutine ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    conn_result = self.db_handler.get_database_connection(tenant_id)
                    
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô coroutine ‡πÉ‡∏´‡πâ await
                    if hasattr(conn_result, '__await__'):
                        conn = await conn_result
                    else:
                        conn = conn_result
                else:
                    conn = await self._create_manual_connection(tenant_id)
                    
            except Exception as db_error:
                logger.warning(f"‚ö†Ô∏è Primary DB connection failed: {db_error}")
                # Fallback to manual sync connection
                conn = self._create_sync_connection(tenant_id)
            
            cursor = conn.cursor()
            
            # Discover all tables
            cursor.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_type = 'BASE TABLE'
                ORDER BY table_name
            """)
            tables = [row[0] for row in cursor.fetchall()]
            
            schema = {}
            for table in tables:
                try:
                    # Get column information
                    cursor.execute(f"""
                        SELECT column_name, data_type, is_nullable, column_default
                        FROM information_schema.columns 
                        WHERE table_name = '{table}' 
                        AND table_schema = 'public'
                        ORDER BY ordinal_position
                    """)
                    
                    columns = []
                    for col_row in cursor.fetchall():
                        col_name, data_type, nullable, default = col_row
                        columns.append({
                            "name": col_name,
                            "type": data_type,
                            "nullable": nullable == "YES",
                            "default": default
                        })
                    
                    # Get sample data (‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô 2 rows ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß)
                    cursor.execute(f"SELECT * FROM {table} LIMIT 2")
                    sample_rows = cursor.fetchall()
                    
                    sample_data = []
                    if sample_rows and cursor.description:
                        sample_data = [dict(zip([desc[0] for desc in cursor.description], row)) 
                                    for row in sample_rows]
                    
                    schema[table] = {
                        "columns": columns,
                        "sample_data": sample_data,
                        "row_count": len(sample_data)
                    }
                    
                except Exception as table_error:
                    logger.warning(f"‚ö†Ô∏è Failed to analyze table {table}: {table_error}")
                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
                    schema[table] = {
                        "columns": [{"name": "id", "type": "integer"}],
                        "sample_data": [],
                        "row_count": 0
                    }
            
            cursor.close()
            conn.close()
            
            # Cache the result
            self.schema_cache[cache_key] = {
                "data": schema,
                "timestamp": datetime.now()
            }
            
            logger.info(f"‚úÖ Schema discovered: {len(tables)} tables")
            return schema
            
        except Exception as e:
            logger.error(f"‚ùå Schema discovery failed: {e}")
            # Return minimal fallback schema
            return {
                "sales2023": {"columns": [{"name": "service_contact_", "type": "integer"}]},
                "sales2024": {"columns": [{"name": "service_contact_", "type": "integer"}]},
                "spare_part": {"columns": [{"name": "product_name", "type": "varchar"}]}
            }

    def _create_sync_connection(self, tenant_id: str):
        """üîó ‡∏™‡∏£‡πâ‡∏≤‡∏á sync database connection (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ async)"""
        
        try:
            import psycopg2
            
            # ‡πÉ‡∏ä‡πâ environment variables ‡∏´‡∏£‡∏∑‡∏≠ default values
            connection_params = {
                'host': os.getenv(f'POSTGRES_HOST_{tenant_id.upper().replace("-", "_")}', 'postgres-company-a'),
                'port': int(os.getenv(f'POSTGRES_PORT_{tenant_id.upper().replace("-", "_")}', '5432')),
                'database': os.getenv(f'POSTGRES_DB_{tenant_id.upper().replace("-", "_")}', 'siamtemp_company_a'),
                'user': os.getenv(f'POSTGRES_USER_{tenant_id.upper().replace("-", "_")}', 'postgres'),
                'password': os.getenv(f'POSTGRES_PASSWORD_{tenant_id.upper().replace("-", "_")}', 'password123')
            }
            
            logger.info(f"üîó Creating sync connection to {connection_params['host']}:{connection_params['port']}")
            return psycopg2.connect(**connection_params)
            
        except Exception as e:
            logger.error(f"‚ùå Sync connection failed: {e}")
            raise

    async def _create_manual_connection(self, tenant_id: str):
        """üîó ‡∏™‡∏£‡πâ‡∏≤‡∏á manual async connection"""
        
        try:
            import asyncpg
            
            connection_string = f"postgresql://postgres:password123@postgres-{tenant_id}:5432/siamtemp_{tenant_id.replace('-', '_')}"
            
            return await asyncpg.connect(connection_string)
            
        except ImportError:
            # asyncpg ‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ sync connection
            return self._create_sync_connection(tenant_id)
    
    # =========================================================================
    # üìù SQL GENERATION WITH SPECIALIST MODEL
    # =========================================================================
    
    async def _generate_sql_with_specialist(self, question: str, schema: Dict[str, Any], tenant_id: str) -> Dict[str, Any]:
        """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç error handling"""
        
        try:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° logging ‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug
            logger.info(f"üîç Creating prompt for: {question}")
            sql_prompt = self._create_business_aware_prompt(question, schema, tenant_id)
            logger.info(f"üìù Prompt length: {len(sql_prompt)}")
            
            # Call SQL Specialist
            logger.info(f"‚è≥ Calling {self.SQL_MODEL}...")
            sql_response = await self._call_ollama_model(self.SQL_MODEL, sql_prompt)
            logger.info(f"‚úÖ Got response: {len(sql_response)} chars")
            
            if not sql_response:
                logger.error("‚ùå Empty response from SQL model")
                return {"success": False, "error": "Empty SQL response"}
            
            # Extract SQL
            sql_query = self._extract_clean_sql(sql_response)
            logger.info(f"üîß Extracted SQL: {sql_query}")
            
            if not sql_query:
                logger.error(f"‚ùå Failed to extract SQL from: {sql_response[:200]}")
                return {"success": False, "error": "SQL extraction failed"}
                
            return {
                "success": True,
                "sql_query": sql_query,
                "analysis": {"model_used": self.SQL_MODEL}
            }
            
        except Exception as e:
            logger.error(f"‚ùå SQL generation error: {str(e)}")
            logger.error(f"‚ùå Question was: {question}")
            return {"success": False, "error": str(e)}

    def _extract_and_validate_sql(self, response: str, schema: Dict[str, Any]) -> Optional[str]:
        """üîß ‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö SQL ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        
        # ‡∏•‡∏ö markdown ‡πÅ‡∏•‡∏∞ formatting
        cleaned_response = re.sub(r'```sql\s*', '', response)
        cleaned_response = re.sub(r'```\s*', '', cleaned_response)
        cleaned_response = cleaned_response.strip()
        
        # ‡∏´‡∏≤ SELECT statement
        sql_patterns = [
            r'(SELECT.*?;)',                                    # Simple SELECT with semicolon
            r'(SELECT.*?FROM\s+\w+.*?(?:ORDER BY.*?)?;?)',      # SELECT with FROM
            r'(SELECT.*?UNION.*?;?)',                           # SELECT with UNION
        ]
        
        for pattern in sql_patterns:
            matches = re.findall(pattern, cleaned_response, re.DOTALL | re.IGNORECASE)
            for match in matches:
                sql = match.strip()
                
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
                sql = re.sub(r'\s+', ' ', sql)
                if not sql.endswith(';'):
                    sql += ';'
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
                if self._is_sql_complete(sql, schema):
                    return sql
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÅ‡∏Ñ‡πà SELECT ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
        select_match = re.search(r'SELECT\s+.*?FROM\s+(\w+)', cleaned_response, re.IGNORECASE | re.DOTALL)
        if select_match:
            table_name = select_match.group(1)
            if table_name in schema:
                # ‡∏û‡∏ö table ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á SQL ‡πÉ‡∏´‡∏°‡πà
                return self._fix_incomplete_sql(cleaned_response, schema)
        
        logger.warning(f"‚ùå No valid SQL found in: {response[:300]}")
        return None

    def _is_sql_complete(self, sql: str, schema: Dict[str, Any]) -> bool:
        """‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö SQL ‡∏ß‡πà‡∏≤‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"""
        
        sql_upper = sql.upper()
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ SELECT ‡πÅ‡∏•‡∏∞ FROM
        if 'SELECT' not in sql_upper or 'FROM' not in sql_upper:
            return False
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ FROM; ‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡πÜ
        if re.search(r'FROM\s*;', sql, re.IGNORECASE):
            return False
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ table name ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á FROM
        from_tables = re.findall(r'FROM\s+(\w+)', sql, re.IGNORECASE)
        if not from_tables:
            return False
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ table ‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô schema
        for table in from_tables:
            if table.lower() not in [t.lower() for t in schema.keys()]:
                logger.warning(f"‚ùå Table {table} not found in schema")
                return False
        
        return True

    def _fix_incomplete_sql(self, sql_response: str, schema: Dict[str, Any]) -> Optional[str]:
        """üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç SQL ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"""
        
        # ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á SELECT
        select_match = re.search(r'(SELECT.*?)(?:FROM|$)', sql_response, re.IGNORECASE | re.DOTALL)
        if not select_match:
            return None
        
        select_part = select_match.group(1).strip()
        
        # ‡∏´‡∏≤ table ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        if '‡∏õ‡∏µ' in sql_response or 'year' in sql_response.lower():
            # ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏µ ‡πÉ‡∏ä‡πâ sales tables
            sales_tables = [t for t in schema.keys() if 'sales' in t.lower()]
            if sales_tables:
                # ‡πÉ‡∏ä‡πâ table ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                main_table = sorted(sales_tables, reverse=True)[0]
                
                fixed_sql = f"""
                {select_part}
                FROM {main_table} 
                WHERE service_contact_ IS NOT NULL 
                AND service_contact_ > 0
                ORDER BY id DESC
                LIMIT 100;
                """
                
                return re.sub(r'\s+', ' ', fixed_sql).strip()
        
        return None

    def _create_business_aware_prompt(self, question: str, schema: Dict[str, Any], tenant_id: str) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
        
        question_lower = question.lower()
        
        # ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ questions
        if any(word in question_lower for word in ['‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤', 'customer']):
            return f"""Generate PostgreSQL to count unique customers.
            
    Tables: sales2024, sales2022 (customer_name column)
    Question: {question}

    Example: SELECT COUNT(DISTINCT customer_name) AS customers FROM sales2024;

    Generate query:"""

        # ‡∏≠‡∏∞‡πÑ‡∏´‡∏•‡πà questions  
        elif any(word in question_lower for word in ['‡∏≠‡∏∞‡πÑ‡∏´‡∏•‡πà', 'motor', '‡∏£‡∏≤‡∏Ñ‡∏≤']):
            return f"""Generate PostgreSQL for spare parts search.
            
    Tables: spare_part, spare_part2
    Columns: product_name, unit_price, description
    Question: {question}

    Example: SELECT product_name, unit_price FROM spare_part WHERE product_name ILIKE '%motor%';

    Generate query:"""

        # ‡∏á‡∏≤‡∏ô PM questions
        elif any(word in question_lower for word in ['pm', '‡∏á‡∏≤‡∏ô pm']):
            return f"""Generate PostgreSQL for PM jobs.
            
    Tables: work_force 
    Columns: job_description_pm (boolean), customer, detail
    Question: {question}

    Example: SELECT COUNT(*) FROM work_force WHERE job_description_pm = true;

    Generate query:"""
        
        elif any(word in question_lower for word in ['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà']):
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏µ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
            month_map = {
                '‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': '01', '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': '02', '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': '03', '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': '04',
                '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': '05', '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': '06', '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': '07', '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': '08',
                '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': '09', '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': '10', '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': '11', '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': '12'
            }
            
            month_code = None
            for month_name, code in month_map.items():
                if month_name in question:
                    month_code = code
                    break
            
            if not month_code:
                month_code = 'XX'  # wildcard
            
            return f"""Generate PostgreSQL for work_force date queries.
            
        Table: work_force
        Date formats: "1-3/06/2025", "26/05/2025 ‚Äì 02/06/2025", "45751"
        Question: {question}

        For month {month_code}: WHERE date LIKE '%/{month_code}/%'
        For any month: WHERE date LIKE '%/MM/%' (replace MM with month number)
        Show work details: SELECT date, customer, detail FROM work_force WHERE condition;

        Generate query:"""
        
        # ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö questions
        elif any(word in question_lower for word in ['‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå']):
            return self._create_comparison_prompt(question, schema)
        
        # Default
        else:
            return f"""Generate simple PostgreSQL query.
    Question: {question}
    Use appropriate table based on question context.
    Generate query:"""

    def _create_schema_prompt_for_sql_coder(self, schema: Dict[str, Any]) -> str:
        """üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á schema prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö SQL Coder"""
        
        prompt = "TABLES AND COLUMNS:\n\n"
        
        for table_name, table_info in schema.items():
            prompt += f"Table: {table_name}\n"
            
            # Show columns with types
            for col in table_info["columns"]:
                prompt += f"  - {col['name']} ({col['type']})\n"
            
            # Show sample data patterns
            if table_info["sample_data"]:
                prompt += "  Sample values:\n"
                sample_row = table_info["sample_data"][0]
                for col_name, value in list(sample_row.items())[:3]:  # First 3 columns
                    if value is not None:
                        prompt += f"    {col_name}: {value}\n"
            
            prompt += "\n"
        
        return prompt
    
    def _extract_clean_sql(self, response: str) -> Optional[str]:
        """üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á SQL ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"""
        
        # ‡∏•‡∏ö prefix ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        response = response.strip()
        lines = response.split('\n')
        
        sql_lines = []
        found_select = False
        
        for line in lines:
            line = line.strip()
            
            # ‡∏Ç‡πâ‡∏≤‡∏° comments ‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á
            if not line or line.startswith(('--', '#', '/*')):
                continue
                
            # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏≤‡∏Å SELECT
            if line.upper().startswith('SELECT'):
                found_select = True
                sql_lines.append(line)
            elif found_select:
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
                if any(keyword in line.upper() for keyword in ['FROM', 'WHERE', 'GROUP', 'ORDER', 'UNION', 'LIMIT', ';']):
                    sql_lines.append(line)
                else:
                    # ‡∏´‡∏¢‡∏∏‡∏î‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
                    break
        
        if sql_lines:
            sql = ' '.join(sql_lines)
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            sql = re.sub(r'\s+', ' ', sql)  # Multiple spaces to single
            sql = sql.replace(' ;', ';')    # Fix spacing before semicolon
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° semicolon ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
            if not sql.rstrip().endswith(';'):
                sql += ';'
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
            if self._validate_sql_completeness(sql):
                return sql
        
        logger.warning(f"‚ùå Could not extract valid SQL from: {response[:200]}...")
        return None

    def _create_year_comparison_prompt(self, question: str, schema: Dict[str, Any]) -> str:
        """üéØ ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏µ"""
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ
        available_sales_tables = [table for table in schema.keys() if 'sales' in table.lower()]
        
        prompt = f"""Generate PostgreSQL query for Thai HVAC sales comparison.

    AVAILABLE SALES TABLES: {', '.join(available_sales_tables)}

    THAI YEAR MAPPING:
    - ‡∏õ‡∏µ 2566 ‚Üí sales2023 table
    - ‡∏õ‡∏µ 2567 ‚Üí sales2024 table
    - ‡∏õ‡∏µ 2568 ‚Üí sales2025 table

    REVENUE COLUMN: service_contact_ (contains revenue amounts)

    QUESTION: {question}

    Required SQL structure for year comparison:
    ```sql
    SELECT 
        '2566' as year,
        COUNT(*) as total_jobs,
        SUM(CAST(service_contact_ AS NUMERIC)) as total_revenue,
        AVG(CAST(service_contact_ AS NUMERIC)) as avg_revenue
    FROM sales2023 
    WHERE service_contact_ IS NOT NULL AND service_contact_ > 0

    UNION ALL

    SELECT 
        '2567' as year,
        COUNT(*) as total_jobs,
        SUM(CAST(service_contact_ AS NUMERIC)) as total_revenue,
        AVG(CAST(service_contact_ AS NUMERIC)) as avg_revenue  
    FROM sales2024
    WHERE service_contact_ IS NOT NULL AND service_contact_ > 0

    ORDER BY year;
    ```

    Generate similar SQL for the question above:"""

        return prompt

    def _validate_sql_completeness(self, sql: str) -> bool:
        """‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á SQL"""
        
        sql_upper = sql.upper()
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ SELECT ‡πÅ‡∏•‡∏∞ FROM
        if 'SELECT' not in sql_upper or 'FROM' not in sql_upper:
            return False
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ table name ‡∏´‡∏•‡∏±‡∏á FROM
        from_match = re.search(r'FROM\s+(\w+)', sql, re.IGNORECASE)
        if not from_match:
            return False
        
        # ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ FROM; ‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡πÜ
        if sql.strip().endswith('FROM;'):
            return False
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
        if len(sql.strip()) < 20:
            return False
        
        return True

    def _validate_sql_security(self, sql: str) -> bool:
        """üîí ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á SQL"""
        
        sql_upper = sql.upper()
        
        # Allow only SELECT statements
        if not sql_upper.strip().startswith('SELECT'):
            return False
        
        # Block dangerous operations
        dangerous_keywords = [
            'DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER', 'CREATE', 
            'TRUNCATE', 'EXEC', 'EXECUTE', 'SP_', 'XP_'
        ]
        
        if any(keyword in sql_upper for keyword in dangerous_keywords):
            return False
        
        return True
    
    def _is_valid_sql_structure(self, sql: str) -> bool:
        """‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á SQL"""
        
        sql_upper = sql.upper()
        
        # Must have SELECT and FROM
        if 'SELECT' not in sql_upper:
            return False
        
        # Should be reasonable length
        if len(sql.strip()) < 10:
            return False
        
        return True
    
    # =========================================================================
    # üí¨ NATURAL LANGUAGE RESPONSE GENERATION
    # =========================================================================
    
    async def _generate_natural_response(self, question: str, results: List[Dict], 
                                    sql_query: str, tenant_id: str) -> str:
        """üí¨ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
        
        if not results:
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á context ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        results_data = self._format_results_for_nl_strict(results)
        
        nl_prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Assistant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó HVAC (‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)

    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô):
    {results_data}

    SQL ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {sql_query}

    ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢:
    1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ - ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡∏°‡πà
    2. ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
    3. ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    4. ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏î‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    5. ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

    ‡∏ï‡∏≠‡∏ö:"""

        try:
            response = await self._call_ollama_model(self.NL_MODEL, nl_prompt)
            cleaned_response = self._clean_and_validate_response(response, results)
            return cleaned_response
            
        except Exception as e:
            logger.error(f"NL generation failed: {e}")
            # Fallback: ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£ format ‡πÅ‡∏ö‡∏ö hardcode
            return self._create_hardcoded_response(question, results)

    def _format_results_for_nl_strict(self, results: List[Dict]) -> str:
        """üìä Format ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ NL model ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î"""
        
        if not results:
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        formatted = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏ö:\n"
        
        for i, row in enumerate(results, 1):
            formatted += f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ {i}: "
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
            data_parts = []
            for key, value in row.items():
                if value is not None and str(value).strip():
                    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏á‡∏¥‡∏ô
                    if key in ['revenue', 'service_contact_', 'total', 'unit_price'] and isinstance(value, (int, float)):
                        formatted_value = f"{value:,.0f} ‡∏ö‡∏≤‡∏ó" if value >= 1000 else f"{value} ‡∏ö‡∏≤‡∏ó"
                        data_parts.append(f"{key}: {formatted_value}")
                    else:
                        data_parts.append(f"{key}: {value}")
            
            formatted += " | ".join(data_parts[:5])  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5 fields
            formatted += "\n"
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        if results and any(isinstance(list(row.values())[0], (int, float)) for row in results):
            formatted += "\n** ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö **\n"
        
        return formatted

    def _clean_and_validate_response(self, response: str, original_results: List[Dict]) -> str:
        """üßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å NL model"""
        
        # ‡∏•‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        response = response.strip()
        response = re.sub(r'^(‡∏ï‡∏≠‡∏ö:|‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:|‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:)', '', response)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        original_numbers = self._extract_numbers_from_results(original_results)
        response_numbers = self._extract_numbers_from_text(response)
        
        # ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
        suspicious_numbers = [n for n in response_numbers if not self._is_number_reasonable(n, original_numbers)]
        
        if suspicious_numbers and len(suspicious_numbers) > len(original_numbers):
            logger.warning(f"Suspicious numbers in response: {suspicious_numbers}")
            # ‡πÉ‡∏ä‡πâ fallback response ‡πÅ‡∏ó‡∏ô
            return self._create_hardcoded_response("", original_results)
        
        return response

    def _extract_numbers_from_results(self, results: List[Dict]) -> List[float]:
        """üî¢ ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏£‡∏¥‡∏á"""
        
        numbers = []
        for row in results:
            for key, value in row.items():
                if isinstance(value, (int, float)) and value > 0:
                    numbers.append(float(value))
        return sorted(numbers, reverse=True)  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢

    def _extract_numbers_from_text(self, text: str) -> List[float]:
        """üî¢ ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        
        # ‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ (‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤)
        number_patterns = [
            r'(\d{1,3}(?:,\d{3})+)',      # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô 17,604,462
            r'(\d+\.\d+)',                # ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô 25.71
            r'(\d+)'                      # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
        ]
        
        numbers = []
        for pattern in number_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                    clean_number = match.replace(',', '')
                    numbers.append(float(clean_number))
                except:
                    continue
        
        return numbers

    def _is_number_reasonable(self, response_number: float, original_numbers: List[float]) -> bool:
        """‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        
        if not original_numbers:
            return True
        
        # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        max_original = max(original_numbers)
        min_original = min(original_numbers)
        
        # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå, ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)
        if response_number <= 100 and len(str(int(response_number))) <= 3:
            return True  # ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
        
        # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏´‡∏ç‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        if response_number > 1000:
            return min_original * 0.1 <= response_number <= max_original * 2
        
        return True

    def _create_hardcoded_response(self, question: str, results: List[Dict]) -> str:
        """üîß ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö hardcode ‡πÄ‡∏°‡∏∑‡πà‡∏≠ NL model ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ"""
        
        if not results:
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if len(results) == 2 and all('period' in row for row in results):
            # ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
            return self._create_comparison_response(results)
        elif len(results) == 1:
            # ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß
            return self._create_single_result_response(results[0])
        else:
            # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
            return self._create_multiple_results_response(results)

    def _create_comparison_response(self, results: List[Dict]) -> str:
        """üìä ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö"""
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• old ‡πÅ‡∏•‡∏∞ new
        old_data = next((r for r in results if r.get('period') == 'old'), None)
        new_data = next((r for r in results if r.get('period') == 'new'), None)
        
        if not old_data or not new_data:
            return "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"
        
        old_jobs = old_data.get('jobs', 0)
        old_revenue = old_data.get('revenue', 0)
        new_jobs = new_data.get('jobs', 0)
        new_revenue = new_data.get('revenue', 0)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
        job_change = ((new_jobs - old_jobs) / old_jobs * 100) if old_jobs > 0 else 0
        revenue_change = ((new_revenue - old_revenue) / old_revenue * 100) if old_revenue > 0 else 0
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        old_avg = (old_revenue / old_jobs) if old_jobs > 0 else 0
        new_avg = (new_revenue / new_jobs) if new_jobs > 0 else 0
        
        response = f"""‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤:

    ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏Å‡πà‡∏≤ (old):
    - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô: {old_jobs:,} ‡∏á‡∏≤‡∏ô
    - ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏°: {old_revenue:,.0f} ‡∏ö‡∏≤‡∏ó
    - ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {old_avg:,.0f} ‡∏ö‡∏≤‡∏ó/‡∏á‡∏≤‡∏ô

    ‡∏ä‡πà‡∏ß‡∏á‡πÉ‡∏´‡∏°‡πà (new):  
    - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô: {new_jobs:,} ‡∏á‡∏≤‡∏ô
    - ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏°: {new_revenue:,.0f} ‡∏ö‡∏≤‡∏ó
    - ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {new_avg:,.0f} ‡∏ö‡∏≤‡∏ó/‡∏á‡∏≤‡∏ô

    ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á:
    - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô: {job_change:+.1f}%
    - ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏°: {revenue_change:+.1f}%"""

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        if revenue_change < 0 and job_change > 0:
            response += "\n\n‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏•‡∏î‡∏•‡∏á ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠‡∏á‡∏≤‡∏ô‡∏•‡∏î‡∏•‡∏á"
        elif revenue_change > job_change:
            response += "\n\n‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï: ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô"
        
        return response

    def _create_single_result_response(self, result: Dict) -> str:
        """üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß"""
        
        response_parts = ["‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:"]
        
        for key, value in result.items():
            if value is not None and str(value).strip():
                if key in ['revenue', 'service_contact_', 'total'] and isinstance(value, (int, float)):
                    response_parts.append(f"- {key}: {value:,.0f} ‡∏ö‡∏≤‡∏ó")
                elif key == 'jobs' and isinstance(value, (int, float)):
                    response_parts.append(f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏≤‡∏ô: {value:,} ‡∏á‡∏≤‡∏ô")
                else:
                    response_parts.append(f"- {key}: {value}")
        
        return "\n".join(response_parts)

    def _create_multiple_results_response(self, results: List[Dict]) -> str:
        """üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"""
        
        response = f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£:\n\n"
        
        for i, row in enumerate(results[:10], 1):  # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
            response += f"{i}. "
            important_fields = []
            
            for key, value in row.items():
                if value is not None and str(value).strip():
                    if key in ['revenue', 'service_contact_', 'total', 'unit_price'] and isinstance(value, (int, float)):
                        important_fields.append(f"{key}: {value:,.0f} ‡∏ö‡∏≤‡∏ó")
                    else:
                        important_fields.append(f"{key}: {value}")
            
            response += " | ".join(important_fields[:4])  # ‡πÅ‡∏™‡∏î‡∏á 4 fields ‡πÅ‡∏£‡∏Å
            response += "\n"
        
        if len(results) > 10:
            response += f"\n... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(results) - 10} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
        
        return response

    
    def _prepare_results_for_nl_model(self, results: List[Dict]) -> str:
        """üìä ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NL Model"""
        
        if not results:
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"
        
        # Limit data to prevent token overflow
        limited_results = results[:10]  
        
        summary = f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(results)}\n\n"
        summary += "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:\n"
        
        for i, row in enumerate(limited_results, 1):
            summary += f"{i}. "
            # Show important fields only
            important_fields = []
            for key, value in row.items():
                if value is not None and str(value).strip():
                    # Prioritize important business fields
                    if key in ['customer_name', 'product_name', 'service_contact_', 'unit_price', 'total', 'job_no', 'description']:
                        important_fields.append(f"{key}: {value}")
            
            summary += " | ".join(important_fields[:4])  # Max 4 fields per row
            summary += "\n"
        
        if len(results) > 10:
            summary += f"\n... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(results) - 10} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
        
        return summary
    
    def _clean_nl_response(self, response: str) -> str:
        """üßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å NL Model"""
        
        # Remove common AI prefixes
        response = re.sub(r'^(‡∏ï‡∏≠‡∏ö:|‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:|‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:)', '', response.strip())
        
        # Remove code blocks if any
        response = re.sub(r'```.*?```', '', response, flags=re.DOTALL)
        
        # Clean up formatting
        response = re.sub(r'\n\s*\n\s*\n', '\n\n', response)  # Multiple newlines to double
        
        return response.strip()
    
    # =========================================================================
    # üîß OLLAMA API INTEGRATION  
    # =========================================================================
    
    async def _call_ollama_model(self, model_name: str, prompt: str) -> str:
        """üîß ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Ollama Model"""
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.request_timeout)) as session:
                payload = {
                    "model": model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1 if "sqlcoder" in model_name.lower() else 0.7,
                        "top_p": 0.9,
                        "top_k": 40
                    }
                }
                
                async with session.post(f"{self.ollama_base_url}/api/generate", json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get("response", "")
                    else:
                        error_text = await response.text()
                        raise Exception(f"Ollama API error: {response.status} - {error_text}")
                        
        except asyncio.TimeoutError:
            raise Exception(f"Timeout calling {model_name}")
        except Exception as e:
            raise Exception(f"Failed to call {model_name}: {e}")
    
    # =========================================================================
    # üóÉÔ∏è DATABASE OPERATIONS
    # =========================================================================

    def _create_enhanced_sqlcoder_prompt(self, question: str, schema: Dict[str, Any], tenant_id: str) -> str:
        """üéØ ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SQL Coder ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏õ‡∏µ 2566/2567"""
        
        # Business Year Mapping (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!)
        year_mapping = """
    YEAR MAPPING FOR THAI BUSINESS:
    - ‡∏õ‡∏µ 2566 = year 2023 = use sales2023 table
    - ‡∏õ‡∏µ 2567 = year 2024 = use sales2024 table  
    - ‡∏õ‡∏µ 2568 = year 2025 = use sales2025 table
    """
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
        schema_text = "DATABASE TABLES:\n"
        for table_name, table_info in schema.items():
            schema_text += f"\nTable: {table_name}\n"
            # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
            important_columns = []
            for col in table_info["columns"]:
                if col["name"] in ["id", "customer_name", "service_contact_", "job_no", 
                                "product_name", "unit_price", "total", "date", "description"]:
                    important_columns.append(f"  {col['name']} ({col['type']})")
            
            if important_columns:
                schema_text += "\n".join(important_columns)
            schema_text += "\n"
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° business rules ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        business_rules = """
    BUSINESS RULES:
    - service_contact_ column = revenue amount (use for sales analysis)
    - For sales comparison: use UNION to combine multiple years
    - For spare parts: search in spare_part and spare_part2 tables
    - Always include WHERE service_contact_ > 0 for revenue calculations
    - Use CAST(service_contact_ AS NUMERIC) for calculations
    """
        
        prompt = f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>

    You are an expert PostgreSQL query generator for Thai HVAC business.

    {year_mapping}

    {schema_text}

    {business_rules}

    IMPORTANT:
    - Generate complete SELECT statements with proper table names
    - For year comparisons, use UNION to combine data from different tables
    - Include proper WHERE clauses
    - Use aggregation functions (SUM, COUNT, AVG) for analysis
    - Always end with semicolon

    <|eot_id|><|start_header_id|>user<|end_header_id|>

    Generate SQL for: {question}

    Requirements:
    - Must be complete valid SQL
    - Include table names in FROM clause
    - Use proper Thai year mapping above

    <|eot_id|><|start_header_id|>assistant<|end_header_id|>

    """
        
        return prompt

    async def _execute_sql_safely(self, sql_query: str, tenant_id: str) -> List[Dict]:
        """üóÉÔ∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô SQL - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á async ‡πÅ‡∏•‡∏∞ sync"""
        
        try:
            # Import datetime ‡πÅ‡∏•‡∏∞ Decimal ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            from datetime import datetime, date
            from decimal import Decimal
            
            # ‡πÉ‡∏ä‡πâ sync connection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ async/sync
            conn = self._create_sync_connection(tenant_id)
            cursor = conn.cursor()
            
            logger.info(f"üìù Executing SQL: {sql_query}")
            
            # Execute query with error handling
            cursor.execute(sql_query)
            rows = cursor.fetchall()
            
            # Convert to dict format
            results = []
            if cursor.description:
                column_names = [desc[0] for desc in cursor.description]
                
                for row in rows:
                    row_dict = {}
                    for i, value in enumerate(row):
                        col_name = column_names[i]
                        # Handle special data types
                        if isinstance(value, (datetime, date)):
                            row_dict[col_name] = value.isoformat()
                        elif isinstance(value, Decimal):  # Handle Decimal type
                            row_dict[col_name] = float(value)
                        elif hasattr(value, '__float__'):  # Handle other numeric types
                            try:
                                row_dict[col_name] = float(value)
                            except:
                                row_dict[col_name] = str(value)
                        else:
                            row_dict[col_name] = value
                    results.append(row_dict)
            
            cursor.close() 
            conn.close()
            
            logger.info(f"‚úÖ SQL executed successfully: {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå SQL execution failed: {e}")
            logger.error(f"‚ùå Failed SQL: {sql_query}")
            return []
        
    async def _get_database_connection(self, tenant_id: str):
        """üîó ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡∏•‡∏ö await ‡∏≠‡∏≠‡∏Å"""
        
        try:
            # ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: psycopg2 connection ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà async
            if hasattr(self.db_handler, 'get_database_connection'):
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô sync function ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ï‡∏£‡∏á ‡πÜ (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà await)
                return self.db_handler.get_database_connection(tenant_id)
            else:
                # Fallback implementation - ‡πÉ‡∏ä‡πâ sync psycopg2
                from .tenant_config import TenantConfigManager
                import psycopg2
                
                config_manager = TenantConfigManager()
                tenant_config = config_manager.tenant_configs[tenant_id]
                
                return psycopg2.connect(
                    host=tenant_config.db_host,
                    port=tenant_config.db_port,
                    database=tenant_config.db_name,
                    user=tenant_config.db_user,
                    password=tenant_config.db_password
                )
                
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            raise

    
    # =========================================================================
    # üîÑ FALLBACK AND ERROR HANDLING
    # =========================================================================
    
    async def _create_fallback_response(self, question: str, tenant_id: str, schema: Dict[str, Any]) -> Dict[str, Any]:
        """üîÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö fallback ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á SQL ‡πÑ‡∏î‡πâ"""
        
        # Analyze available data
        table_summary = self._create_schema_summary(schema)
        
        fallback_answer = f"""ü§î ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° "{question}" ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

{table_summary}

üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
‚Ä¢ ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
‚Ä¢ ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à HVAC

üéØ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ:
‚Ä¢ "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
‚Ä¢ "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏≠‡∏∞‡πÑ‡∏´‡∏•‡πà MOTOR"
‚Ä¢ "‡∏á‡∏≤‡∏ô‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ"

‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö!"""

        return {
            "answer": fallback_answer,
            "success": False,
            "sql_query": None,
            "results_count": 0,
            "system_used": "fallback_response",
            "processing_time": 0.5
        }
    
    def _create_schema_summary(self, schema: Dict[str, Any]) -> str:
        """üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"""
        
        summary = "üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:\n"
        
        for table_name, table_info in schema.items():
            row_count = table_info.get("row_count", 0)
            col_count = len(table_info.get("columns", []))
            
            # Table description based on name
            if "sales" in table_name:
                description = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£"
            elif "spare" in table_name:
                description = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∞‡πÑ‡∏´‡∏•‡πà‡πÅ‡∏•‡∏∞‡∏™‡∏ï‡πá‡∏≠‡∏Å" 
            elif "work" in table_name:
                description = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡∏°"
            else:
                description = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"
            
            summary += f"‚Ä¢ {table_name}: {description} ({col_count} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)\n"
        
        return summary
    
    def _create_simple_formatted_response(self, question: str, results: List[Dict]) -> str:
        """üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏°‡∏∑‡πà‡∏≠ NL Model ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß"""
        
        if not results:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}"
        
        response = f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {question}\n\n"
        response += f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£:\n\n"
        
        for i, row in enumerate(results[:5], 1):  # Show first 5 results
            response += f"{i}. "
            # Show important fields
            important_data = []
            for key, value in row.items():
                if value is not None and str(value).strip():
                    important_data.append(f"{key}: {value}")
            
            response += " | ".join(important_data[:3])  # Show first 3 fields
            response += "\n"
        
        if len(results) > 5:
            response += f"\n... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(results) - 5} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
        
        return response
    
    def _create_error_response(self, error_message: str, tenant_id: str) -> Dict[str, Any]:
        """‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î"""
        
        return {
            "answer": f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {error_message}",
            "success": False,
            "sql_query": None,
            "results_count": 0,
            "system_used": "error_handler",
            "processing_time": 0.1
        }

# =============================================================================
# üîß ENHANCED AGENT WITH DUAL-MODEL INTEGRATION
# =============================================================================

class EnhancedUnifiedPostgresOllamaAgent:
    """üöÄ Enhanced Agent ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Dual-Model Strategy"""
    
    def __init__(self):
        try:
            # Import original agent
            from .enhanced_postgres_agent_unified import UnifiedEnhancedPostgresOllamaAgent as OriginalAgent
            
            # Initialize original agent
            original_agent = OriginalAgent()
            
            # Copy all attributes and methods
            for attr_name in dir(original_agent):
                if not attr_name.startswith('__'):
                    setattr(self, attr_name, getattr(original_agent, attr_name))
            
            # Add Dual-Model AI System
            self.dual_model_ai = DualModelDynamicAISystem(self, self)
            self.STRICT_MODE = True  # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
            self.VALIDATION_ENABLED = True 

            logger.info("üöÄ Enhanced Agent with Dual-Model AI initialized")
            logger.info(f"   üìù SQL Model: {self.dual_model_ai.SQL_MODEL}")
            logger.info(f"   üí¨ NL Model: {self.dual_model_ai.NL_MODEL}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Enhanced Agent with Dual-Model: {e}")
            raise
    
    async def process_any_question(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """üéØ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Dual-Model Strategy"""
        return await self.dual_model_ai.process_any_question(question, tenant_id)
    
    async def process_enhanced_question_with_dual_model(self, question: str, tenant_id: str) -> Dict[str, Any]:
        """üîÑ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Dual-Model ‡∏û‡∏£‡πâ‡∏≠‡∏° fallback"""
        
        try:
            # Try Dual-Model approach first
            result = await self.dual_model_ai.process_any_question(question, tenant_id)
            
            if result.get("success") and result.get("results_count", 0) > 0:
                return result
            
            # Fallback to original method
            logger.info("üîÑ Dual-Model failed, using original method")
            return await self.process_enhanced_question(question, tenant_id)
            
        except Exception as e:
            logger.error(f"‚ùå All methods failed: {e}")
            return self._create_error_response(str(e), tenant_id)